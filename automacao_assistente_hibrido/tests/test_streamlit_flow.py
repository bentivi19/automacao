#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Simular EXATAMENTE o fluxo do Streamlit
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model_handlers import model_manager
from memorystore import MemoryStore
from PIL import Image
import io

print("=" * 70)
print("üîç SIMULANDO FLUXO DO STREAMLIT")
print("=" * 70)

# Setup
memory_store = MemoryStore()

# 1. Simular upload de imagem
print("\n1Ô∏è‚É£ Simulando upload de imagem...")
img = Image.new('RGB', (200, 200), color='green')
img_bytes = io.BytesIO()
img.save(img_bytes, format='PNG')
img_bytes.seek(0)
img_data = img_bytes.getvalue()
print(f"   ‚úÖ Imagem: {len(img_data)} bytes (verde)")

# 2. Simular input do usu√°rio
user_input = "O que voc√™ v√™ nessa imagem?"
print(f"\n2Ô∏è‚É£ Input do usu√°rio: '{user_input}'")

# 3. Simular sele√ß√£o de modelo
provider = "OpenAI"
model = "üì± GPT-4o-mini (Vis√£o)"
print(f"\n3Ô∏è‚É£ Modelo selecionado:")
print(f"   Provider: {provider}")
print(f"   Model: {model}")

# 4. Simular fun√ß√£o call_model
def call_model(prompt, img_data=None):
    # Buscar notas relevantes ANTES de fazer a pergunta (apenas se n√£o tiver imagem/v√≠deo/√°udio)
    if not img_data:
        notas_relevantes = memory_store.search_notes(prompt, limit=3)
    else:
        notas_relevantes = []
    
    # Construir contexto com as notas
    contexto = ''
    if notas_relevantes:
        contexto = '\n\n[CONTEXTO DE NOTAS ANTERIORES]\n'
        for nota in notas_relevantes:
            if nota.get('question') and nota.get('answer'):
                contexto += f"\nPergunta: {nota.get('question')}\nResposta: {nota.get('answer')}\n"
            else:
                contexto += f"\nNota: {nota.get('text')}\n"
        contexto += '\n[FIM DO CONTEXTO]\n\n'
    
    # Montar prompt com contexto (simples, sem adicionar "Pergunta do usuario")
    prompt_final = contexto + prompt if contexto else prompt
    
    print(f"\n   üîπ Prompt final enviado ao modelo:")
    print(f"      '{prompt_final}'")
    print(f"   üîπ Tem img_data? {img_data is not None}")
    print(f"   üîπ Tamanho img_data: {len(img_data) if img_data else 0} bytes")
    
    # Chamar modelo selecionado
    resultado = model_manager.generate(provider, model, prompt_final, img_data)
    
    print(f"\n   üìç Resposta do modelo:")
    print(f"      {resultado}")
    
    return resultado

# 5. Processar imagem
print(f"\n4Ô∏è‚É£ Processando imagem com call_model...")
resultado = call_model(f'Imagem: {user_input}', img_data=img_data)

# 6. Validar resultado
print(f"\n5Ô∏è‚É£ Valida√ß√£o:")
if "verde" in resultado.lower() or "green" in resultado.lower():
    print(f"   ‚úÖ SUCESSO! Modelo identificou a cor verde!")
else:
    print(f"   ‚ùå FALHA: Modelo n√£o identificou a cor corretamente")
    print(f"   Resposta: {resultado}")

print("\n" + "=" * 70)
